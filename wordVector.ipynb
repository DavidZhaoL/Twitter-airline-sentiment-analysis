{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "U:\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "U:\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "U:\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "U:\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "U:\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "U:\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"Tweets.csv\"\n",
    "airline_tweets =pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=airline_tweets.iloc[:,10].values\n",
    "processed_features=[]\n",
    "\n",
    "for sentence in range(0, len(features)):\n",
    "    # Remove all the special characters\n",
    "    processed_feature = re.sub(r'\\W', ' ', str(features[sentence]))\n",
    "\n",
    "    # remove all single characters\n",
    "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    processed_feature = processed_feature.lower()\n",
    "    processed_features.append(processed_feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " virginamerica what dhepburn said \n"
     ]
    }
   ],
   "source": [
    "len(processed_features)\n",
    "print(processed_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "labels=pd.get_dummies(airline_tweets['airline_sentiment']).values\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#labels[labels=='negative']=0\n",
    "#labels[labels=='neutral']=1\n",
    "#labels[labels=='positive']=2\n",
    "#print(type(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(2928, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(processed_features,labels,test_size=0.2,random_state=42)\n",
    "\n",
    "max_length=max([len(s.split()) for s in processed_features])\n",
    "tokenizer_obj=Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(processed_features)\n",
    "\n",
    "print(type(y_test))\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokens=tokenizer_obj.texts_to_sequences(X_train)\n",
    "X_test_tokens=tokenizer_obj.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad=pad_sequences(X_train_tokens,maxlen=max_length,padding='post')\n",
    "X_test_pad=pad_sequences(X_test_tokens,maxlen=max_length,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(tokenizer_obj.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Model....\n",
      "Sucessfully build model...\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Dense,Embedding,LSTM,GRU\n",
    "\n",
    "EMBEDDINGS=150\n",
    "\n",
    "print('Build Model....')\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size,EMBEDDINGS,input_length=max_length))\n",
    "model.add(GRU(units=32,dropout=0.4,recurrent_dropout=0.4))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "\n",
    "print('Sucessfully build model...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning......\n",
      "Epoch 1/35\n",
      " - 6s - loss: 0.9433 - acc: 0.6105\n",
      "Epoch 2/35\n",
      " - 4s - loss: 0.9202 - acc: 0.6224\n",
      "Epoch 3/35\n",
      " - 4s - loss: 0.7889 - acc: 0.6539\n",
      "Epoch 4/35\n",
      " - 4s - loss: 0.6018 - acc: 0.7334\n",
      "Epoch 5/35\n",
      " - 4s - loss: 0.4835 - acc: 0.8016\n",
      "Epoch 6/35\n",
      " - 4s - loss: 0.3869 - acc: 0.8513\n",
      "Epoch 7/35\n",
      " - 4s - loss: 0.3060 - acc: 0.8907\n",
      "Epoch 8/35\n",
      " - 4s - loss: 0.2393 - acc: 0.9168\n",
      "Epoch 9/35\n",
      " - 4s - loss: 0.1871 - acc: 0.9373\n",
      "Epoch 10/35\n",
      " - 4s - loss: 0.1493 - acc: 0.9525\n",
      "Epoch 11/35\n",
      " - 4s - loss: 0.1215 - acc: 0.9611\n",
      "Epoch 12/35\n",
      " - 4s - loss: 0.1076 - acc: 0.9655\n",
      "Epoch 13/35\n",
      " - 4s - loss: 0.0946 - acc: 0.9702\n",
      "Epoch 14/35\n",
      " - 4s - loss: 0.0834 - acc: 0.9730\n",
      "Epoch 15/35\n",
      " - 4s - loss: 0.0726 - acc: 0.9786\n",
      "Epoch 16/35\n",
      " - 4s - loss: 0.0698 - acc: 0.9786\n",
      "Epoch 17/35\n",
      " - 4s - loss: 0.0653 - acc: 0.9793\n",
      "Epoch 18/35\n",
      " - 4s - loss: 0.0554 - acc: 0.9834\n",
      "Epoch 19/35\n",
      " - 4s - loss: 0.0556 - acc: 0.9836\n",
      "Epoch 20/35\n",
      " - 4s - loss: 0.0532 - acc: 0.9828\n",
      "Epoch 21/35\n",
      " - 4s - loss: 0.0462 - acc: 0.9863\n",
      "Epoch 22/35\n",
      " - 4s - loss: 0.0462 - acc: 0.9852\n",
      "Epoch 23/35\n",
      " - 4s - loss: 0.0431 - acc: 0.9855\n",
      "Epoch 24/35\n",
      " - 4s - loss: 0.0415 - acc: 0.9877\n",
      "Epoch 25/35\n",
      " - 4s - loss: 0.0401 - acc: 0.9878\n",
      "Epoch 26/35\n",
      " - 4s - loss: 0.0370 - acc: 0.9889\n",
      "Epoch 27/35\n",
      " - 4s - loss: 0.0390 - acc: 0.9878\n",
      "Epoch 28/35\n",
      " - 4s - loss: 0.0375 - acc: 0.9875\n",
      "Epoch 29/35\n",
      " - 4s - loss: 0.0356 - acc: 0.9887\n",
      "Epoch 30/35\n",
      " - 4s - loss: 0.0324 - acc: 0.9895\n",
      "Epoch 31/35\n",
      " - 4s - loss: 0.0329 - acc: 0.9892\n",
      "Epoch 32/35\n",
      " - 4s - loss: 0.0343 - acc: 0.9879\n",
      "Epoch 33/35\n",
      " - 4s - loss: 0.0305 - acc: 0.9905\n",
      "Epoch 34/35\n",
      " - 4s - loss: 0.0298 - acc: 0.9898\n",
      "Epoch 35/35\n",
      " - 4s - loss: 0.0292 - acc: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1403f092438>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Traning......')\n",
    "model.fit(X_train_pad,y_train,batch_size=128,epochs=35,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "prediction=model.predict(X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2928"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2928, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7585382513661202\n"
     ]
    }
   ],
   "source": [
    "true_count=0\n",
    "\n",
    "for i in range(len(prediction)):\n",
    "    p=np.argmax(prediction[i])\n",
    "    q=np.argmax(y_test[i])\n",
    "    \n",
    "    if p==q:\n",
    "        true_count+=1\n",
    "print(true_count/len(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
